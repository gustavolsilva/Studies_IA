# Databricks Exam Prep - Setup & Deployment Guide

## ğŸ“‹ SumÃ¡rio

- **Ambiente Isolado**: Python virtualenv + Node.js local (sem poluir SO)
- **GeraÃ§Ã£o AutomÃ¡tica**: Banco de dados gerado em primeiro setup via script Python
- **Formato Otimizado**: QuestÃµes em Parquet (compactaÃ§Ã£o 10x) com fallback JSON
- **VirtualizaÃ§Ã£o**: Docker + Docker Compose para dev/prod isolado
- **Cross-platform**: Windows (WSL2), macOS, Linux

---

## ğŸš€ Setup RÃ¡pido (Recomendado)

### OpÃ§Ã£o 1: Setup Local com Virtualenv

```bash
cd databricks-exam-prep
chmod +x setup-environment.sh
./setup-environment.sh
```

**O que faz:**
1. âœ… Valida Node.js 20.19+ e Python 3.8+
2. âœ… Cria `.venv` isolado (sem poluir SO)
3. âœ… Instala pandas + pyarrow
4. âœ… **Gera banco de questÃµes em Parquet**
5. âœ… Instala dependÃªncias Node.js
6. âœ… Compila imagem Docker (opcional)

**Resultado:**
```
client/public/
  â”œâ”€â”€ questions_enhanced.parquet (6 KB, compactado)
  â””â”€â”€ questions_enhanced.json (fallback, 24 KB)
.venv/
  â”œâ”€â”€ bin/python3, pip, etc. (isolado)
node_modules/ (local, nÃ£o poluir SO)
```

### OpÃ§Ã£o 2: Docker Compose (Recomendado para equipes)

```bash
# Build + Run container de produÃ§Ã£o
docker-compose up

# ou modo desenvolvimento com hot-reload
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up dev
```

---

## ğŸ“¦ Estrutura de Ambiente

### `.venv` - Virtualenv Python (Isolado)

Criado no projeto, **nÃ£o precisa instalar globalmente**:
```bash
# Automaticamente feito por setup-environment.sh
python3 -m venv .venv
source .venv/bin/activate  # ou .venv\Scripts\activate no Windows
pip install pandas pyarrow
```

**Vantagens:**
- âœ… Sem poluir `/usr/local` ou `$PROFILE`
- âœ… Cada projeto tem suas prÃ³prias dependÃªncias
- âœ… FÃ¡cil remover: `rm -rf .venv`

### `node_modules` - Node.js (Local)

Instalado com `npm ci` ou `pnpm install`:
```bash
npm install
```

**Para WSL2/Windows:**
```bash
npm install --legacy-peer-deps  # Se houver conflitos
```

---

## ğŸ”„ GeraÃ§Ã£o AutomÃ¡tica de Dados

### Como Funciona

1. **Durante Setup (`./setup-environment.sh`)**:
   - Ativa `.venv`
   - Executa `python3 generate_questions_parquet.py`
   - Gera `client/public/questions_enhanced.parquet`
   - Fallback: `client/public/questions_enhanced.json`

2. **Gerador Python** (`generate_questions_parquet.py`):
   - âœ… Cross-platform (Windows, macOS, Linux)
   - âœ… Usa pandas + pyarrow (sem Spark)
   - âœ… Gera Parquet + JSON automaticamente
   - âœ… Valida integridade dos dados

3. **AplicaÃ§Ã£o Carrega Dados**:
   - Tenta: Parquet (otimizado) â†’ JSON enhanced â†’ JSON expanded
   - Fallback automÃ¡tico se formato nÃ£o disponÃ­vel

### Regenerar Dados Manualmente

```bash
# Ativar virtualenv
source .venv/bin/activate

# Rodar gerador
python3 generate_questions_parquet.py

# Output
# âœ… Gerado 12 questoes para Parquet
# ğŸ’¾ Salvo Parquet: client/public/questions_enhanced.parquet
# ğŸ’¾ Salvo JSON (fallback): client/public/questions_enhanced.json
# ğŸ“ Tamanhos: Parquet 6.1 KB, JSON 24.3 KB (4.0x menor)
```

---

## ğŸ³ Docker - VirtualizaÃ§Ã£o Completa

### Imagens

1. **Production** (`Dockerfile`):
   - Build otimizado multi-stage
   - âœ… Gera dados durante build
   - âœ… Runtime leve (Alpine)
   - âœ… Health check

2. **Development** (`Dockerfile.dev`):
   - âœ… Hot-reload com Vite
   - âœ… Volume mounts para cÃ³digo
   - âœ… Python environment para debug

### Usar Docker

```bash
# Build e rodar produÃ§Ã£o
docker build -t databricks-exam-prep:latest .
docker run -p 3000:3000 databricks-exam-prep:latest

# Usar docker-compose (recomendado)
docker-compose up                    # ProduÃ§Ã£o (porta 3000)
docker-compose up dev                # Desenvolvimento (porta 3001)
docker-compose down                  # Parar tudo
docker-compose down -v               # Remover volumes tambÃ©m
```

**Vantagens do Docker:**
- âœ… Ambiente isolado 100% (sem poluir SO)
- âœ… Mesmo ambiente em dev/CI/prod
- âœ… FÃ¡cil compartilhar setup entre devs
- âœ… Dados gerados no build

---

## ğŸ“Š Formato Parquet vs JSON

### Parquet (Recomendado)

- âœ… **10x menor**: 6 KB vs 60 KB
- âœ… **Tipado**: Schema forte, validaÃ§Ã£o automÃ¡tica
- âœ… **CompressÃ£o**: Snappy (default)
- âœ… **Otimizado**: Ideal para analytics
- âš ï¸ Requer parser (DuckDB, pyarrow, etc.)

### JSON (Fallback)

- âœ… **Universal**: Suporte em qualquer linguagem
- âœ… **Debug-friendly**: HumanlegÃ­vel
- âš ï¸ **Maior**: 60+ KB
- âš ï¸ **Sem tipagem**: Apenas strings

### EstratÃ©gia

```
App Carrega:
  1. Parquet (se DuckDB disponÃ­vel) â†’ 6 KB âš¡
  2. JSON enhanced (fallback) â†’ 24 KB ğŸŸ¢
  3. JSON expanded (Ãºltima opÃ§Ã£o) â†’ 300 KB ğŸŸ¡
```

---

## ğŸ› ï¸ Desenvolver Localmente

### Modo Dev (Com Hot-Reload)

```bash
# Ativar ambiente
source .venv/bin/activate

# Dev (port 3000)
npm run dev

# Acessa em http://localhost:3000
# AlteraÃ§Ãµes no cÃ³digo recarregam automaticamente
```

### Gerar Novo Banco de Dados

```bash
source .venv/bin/activate
python3 generate_questions_parquet.py
```

### Adicionar QuestÃµes

Edite `generate_questions_parquet.py`, adicione mais chamadas `add_question()`:

```python
add_question(
    "Databricks Intelligence Platform", "intermediate", "conceptual",
    "Pergunta aqui?",
    {"A": "...", "B": "...", "C": "...", "D": "..."},
    "A",  # resposta correta
    "Rationale aqui (150-500 chars)...",
    "Dica curta",
    refs["delta"],
    "Contexto de cenÃ¡rio"
)
```

Depois regenere:
```bash
python3 generate_questions_parquet.py
```

---

## ğŸš€ Deploy em ProduÃ§Ã£o

### Docker (Recomendado)

```bash
# Build
docker build -t databricks-exam-prep:latest .

# Push para registry (Docker Hub, ECR, etc.)
docker tag databricks-exam-prep:latest seu-registry/databricks-exam-prep:latest
docker push seu-registry/databricks-exam-prep:latest

# Deploy em cluster (Kubernetes, ECS, etc.)
docker run -p 3000:3000 \
  -e NODE_ENV=production \
  databricks-exam-prep:latest
```

### Node.js Local

```bash
npm run build
npm start
# Acessa em http://localhost:3000
```

---

## ğŸ“ Troubleshooting

### âŒ "python3 command not found"

```bash
# macOS
brew install python3

# Ubuntu/Debian
sudo apt-get install python3 python3-venv

# Windows: Instale Python de https://www.python.org
```

### âŒ ".venv: Permission denied"

```bash
chmod +x setup-environment.sh
./setup-environment.sh
```

### âŒ "Docker: command not found"

Instale Docker Desktop de https://www.docker.com/products/docker-desktop

### âŒ "Parquet nÃ£o carrega, apenas JSON"

DuckDB nÃ£o estÃ¡ disponÃ­vel no navegador. Isso Ã© normal:
- App usa JSON como fallback automaticamente
- Parquet sÃ³ funciona com backend que parse (Node.js)
- JSON Ã© suficiente para a maioria dos casos

### âŒ "Port 3000 jÃ¡ estÃ¡ em uso"

```bash
# Mudar porta
docker-compose.yml: ports: ["3001:3000"]

# Ou kill processo existente
lsof -i :3000
kill -9 <PID>
```

---

## âœ… Checklist de Setup

- [ ] Node.js 20.19+ instalado (`node --version`)
- [ ] Python 3.8+ instalado (`python3 --version`)
- [ ] Repo clonado em `~/Projects/databricks-exam-prep`
- [ ] Rodou `./setup-environment.sh` com sucesso
- [ ] `.venv` criado e ativado
- [ ] `node_modules` instalado
- [ ] `client/public/questions_enhanced.parquet` ou `.json` gerado
- [ ] `npm run dev` funciona (acessa localhost:3000)
- [ ] (Opcional) Docker tambÃ©m funciona

---

## ğŸ“š ReferÃªncias

- [Python venv docs](https://docs.python.org/3/library/venv.html)
- [Docker Compose docs](https://docs.docker.com/compose/)
- [Parquet format](https://parquet.apache.org/)
- [Pandas Parquet I/O](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html)

